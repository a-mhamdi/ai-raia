{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5cedd213-90cc-4106-91d3-ec0ac4c8ff65",
   "metadata": {},
   "source": [
    "# VARIATIONAL AUTOENCODER (VAE)\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58bdb6b7-1714-405f-8112-699ff9c37c6a",
   "metadata": {},
   "source": [
    "VAE implemented in `Julia` using the `Flux.jl` library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "beab227b-2d88-4b30-ac4d-52f0ebbaf1c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Julia Version 1.11.2\n",
      "Commit 5e9a32e7af2 (2024-12-01 20:02 UTC)\n",
      "Build Info:\n",
      "  Official https://julialang.org/ release\n",
      "Platform Info:\n",
      "  OS: Linux (x86_64-linux-gnu)\n",
      "  CPU: 8 × Intel(R) Core(TM) i7-8565U CPU @ 1.80GHz\n",
      "  WORD_SIZE: 64\n",
      "  LLVM: libLLVM-16.0.6 (ORCJIT, skylake)\n",
      "Threads: 1 default, 0 interactive, 1 GC (on 8 virtual cores)\n",
      "Environment:\n",
      "  LD_LIBRARY_PATH = /home/mhamdi/torch/install/lib:/home/mhamdi/torch/install/lib:/home/mhamdi/torch/install/lib:\n",
      "  DYLD_LIBRARY_PATH = /home/mhamdi/torch/install/lib:/home/mhamdi/torch/install/lib:/home/mhamdi/torch/install/lib:\n",
      "  JULIA_NUM_THREADS = 8\n"
     ]
    }
   ],
   "source": [
    "versioninfo() # -> v\"1.11.2\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d9d8e2d6-eb3d-4446-a59a-dc8927ea4449",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m\u001b[1m  Activating\u001b[22m\u001b[39m project at `~/Work/git-repos/AI-ML-DL/jlai/Codes/Julia/Part-3/vae`\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m\u001b[1mStatus\u001b[22m\u001b[39m `~/Work/git-repos/AI-ML-DL/jlai/Codes/Julia/Part-3/vae/Project.toml`\n",
      "  \u001b[90m[587475ba] \u001b[39mFlux v0.16.0\n",
      "  \u001b[90m[eb30cadb] \u001b[39mMLDatasets v0.7.18\n",
      "  \u001b[90m[91a5bcdd] \u001b[39mPlots v1.40.9\n",
      "  \u001b[90m[c3e4b0f8] \u001b[39mPluto v0.20.4\n",
      "  \u001b[90m[7f904dfe] \u001b[39mPlutoUI v0.7.60\n",
      "  \u001b[90m[92933f4c] \u001b[39mProgressMeter v1.10.2\n",
      "  \u001b[90m[d6f4376e] \u001b[39mMarkdown v1.11.0\n"
     ]
    }
   ],
   "source": [
    "using Pkg; pkg\"activate .\"; pkg\"status\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09828e35-8f57-48bf-acee-2eedec9c3557",
   "metadata": {},
   "source": [
    "Import the machine learning library `Flux`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "127ab0b7-5b37-4265-a66e-4c35d7df1ba6",
   "metadata": {},
   "outputs": [],
   "source": [
    "using Flux # v\"0.16.0\"\n",
    "using Flux: @functor\n",
    "using Flux: DataLoader\n",
    "using Flux: onecold, onehotbatch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ed08fb17-bcad-4ee8-ab55-0a11588804ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "using ProgressMeter: Progress, next!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f7c37037-9d7e-4e72-8346-f8328326c610",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dataset MNIST:\n",
       "  metadata  =>    Dict{String, Any} with 3 entries\n",
       "  split     =>    :train\n",
       "  features  =>    28×28×60000 Array{Float32, 3}\n",
       "  targets   =>    60000-element Vector{Int64}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "using MLDatasets\n",
    "d = MNIST()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "74719038-eea2-4101-b795-71f3210c040c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "HyperParams"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Base.@kwdef mutable struct HyperParams\n",
    "    η = 3f-3                        # Learning rate\n",
    "    λ = 1f-2                        # Regularization parameter\n",
    "    batchsize = 64                  # Batch size\n",
    "    epochs = 16                     # Number of epochs\n",
    "    split = :train                  # Split data into `train` and `test`\n",
    "    input_dim = 28*28               # Input dimension\n",
    "    hidden_dim = 512                # Hidden dimension\n",
    "    latent_dim = 2                  # Latent dimension\n",
    "    # save_path = \"Output\"          # Results folder\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d86adcb-099a-4afc-b554-0717640aae0c",
   "metadata": {},
   "source": [
    "Load the **MNIST** dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bc126bdd-1dfd-44c1-b6fb-bfa019516e44",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "get_data (generic function with 1 method)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function get_data(; kws...)\n",
    "    args = HyperParams(; kws...);\n",
    "    # Split data\n",
    "    data = MNIST(split=args.split);\n",
    "    X = reshape(data.features, (args.input_dim, :));\n",
    "    loader = DataLoader(X; batchsize=args.batchsize, shuffle=true);\n",
    "    return loader\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5e8eeff3-a9db-42de-9005-aa5cc2adfa13",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = get_data();\n",
    "test_loader = get_data(split=:test);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc40899e-5ae7-4e21-8315-cc3c9fb71571",
   "metadata": {},
   "source": [
    "Define the `encoder` network: The encoder network should return the parameters of the _latent distribution_ (μ and σ)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "79fcdbea-c6d4-4d51-ab1f-e75fb33940ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "struct Encoder\n",
    "    linear\n",
    "    μ\n",
    "    log_σ\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9f1c171e-a2f6-4a65-9843-6f7f5ec3a46c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[33m\u001b[1m┌ \u001b[22m\u001b[39m\u001b[33m\u001b[1mWarning: \u001b[22m\u001b[39mThe use of `Flux.@functor` is deprecated.\n",
      "\u001b[33m\u001b[1m│ \u001b[22m\u001b[39mMost likely, you should write `Flux.@layer MyLayer`which will add various convenience methods for your type,such as pretty-printing and use with Adapt.jl.\n",
      "\u001b[33m\u001b[1m│ \u001b[22m\u001b[39mHowever, this is not required. Flux.jl v0.15 uses Functors.jl v0.5,which makes exploration of most nested `struct`s opt-out instead of opt-in...so Flux will automatically see inside any custom struct definitions.\n",
      "\u001b[33m\u001b[1m│ \u001b[22m\u001b[39mIf you really want to apply the `@functor` macro to a custom struct, use `Functors.@functor` instead.\n",
      "\u001b[33m\u001b[1m└ \u001b[22m\u001b[39m\u001b[90m@ Flux ~/.julia/packages/Flux/Mhg1r/src/deprecations.jl:101\u001b[39m\n"
     ]
    }
   ],
   "source": [
    "@functor Encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5f6dfed6-ee27-4d16-89da-510dde2e132d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "encoder (generic function with 1 method)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoder(input_dim::Int, hidden_dim::Int, latent_dim::Int) = Encoder(\n",
    "    Dense(input_dim, hidden_dim, tanh),   # linear\n",
    "    Dense(hidden_dim, latent_dim),        # μ\n",
    "    Dense(hidden_dim, latent_dim),        # log_σ\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "938a17e8-4a49-46ab-815a-73fd70cd2e46",
   "metadata": {},
   "outputs": [],
   "source": [
    "function (encoder::Encoder)(x)\n",
    "    h = encoder.linear(x)\n",
    "    encoder.μ(h), encoder.log_σ(h)\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b653535-0cfb-44e7-ab0f-363638bb0cd5",
   "metadata": {},
   "source": [
    "Define the `decoder` network: The decoder network should return the reconstruction of the input data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6bc6817b-1f4a-4d65-89ca-8d9ede2f4b11",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "decoder (generic function with 1 method)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "decoder(input_dim::Int, hidden_dim::Int, latent_dim::Int) = Chain(\n",
    "    Dense(latent_dim, hidden_dim, tanh),\n",
    "    Dense(hidden_dim, input_dim)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7dca5ce8-aced-43b8-9c01-75a7893153ef",
   "metadata": {},
   "source": [
    "Reconstruction of the input data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9ae574d6-17b2-4aba-8749-09d2b84bf95c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "vae (generic function with 1 method)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function vae(x, enc, dec)\n",
    "    # Encode `x` into the latent space\n",
    "    μ, log_σ = enc(x)\n",
    "    # `z` si a sample from the latent distribution\n",
    "    z = μ + randn(Float32, size(log_σ)) .* exp.(log_σ)\n",
    "    # Decode the latent representation into a reconstruction of `x`\n",
    "    x̂ = dec(z)\n",
    "    # Return μ, log_σ and x̂\n",
    "    μ, log_σ, x̂\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "99660b4d-c3ce-469c-bb9c-fdd86a3feb13",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "l (generic function with 1 method)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function l(x, enc, dec, λ)\n",
    "    μ, log_σ, x̂ = vae(x, enc, dec)\n",
    "    len = size(x)[end]\n",
    "    # The reconstruction loss measures how well the VAE was able to reconstruct the input data\n",
    "    logp_x_z = -Flux.Losses.logitbinarycrossentropy(x̂, x, agg=sum) / len\n",
    "    # The KL divergence loss measures how close the latent distribution is to the normal distribution\n",
    "    kl_q_p = 5f-1 * sum(@. (-2f0 * log_σ - 1f0 + exp(2f0 * log_σ) + μ^2)) / len\n",
    "    # L2 Regularization\n",
    "    reg = λ * sum( θ -> sum(θ.^2), Flux.params(dec) )\n",
    "    # Sum of the reconstruction loss and the KL divergence loss\n",
    "    -logp_x_z + kl_q_p + reg\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e8ace135-e555-4266-a007-ae7c91b3adc7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "train (generic function with 1 method)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function train(; kws...)\n",
    "    args = HyperParams(; kws...)\n",
    "    \n",
    "    # Initialize `encoder` and `decoder`\n",
    "    enc_mdl = encoder(args.input_dim, args.hidden_dim, args.latent_dim)\n",
    "    dec_mdl = decoder(args.input_dim, args.hidden_dim, args.latent_dim)\n",
    "    \n",
    "    # ADAM optimizers\n",
    "    opt_enc = Flux.setup(Adam(args.η), enc_mdl)\n",
    "    opt_dec = Flux.setup(Adam(args.η), dec_mdl)\n",
    "\n",
    "    for epoch in 1:args.epochs\n",
    "        printstyled(\"\\t***\\t === EPOCH $(epoch) === \\t*** \\n\", color=:magenta, bold=true)\n",
    "        progress = Progress(length(train_loader))\n",
    "        for X in train_loader\n",
    "                loss, back = Flux.pullback(enc_mdl, dec_mdl) do enc, dec\n",
    "                    l(X, enc, dec, args.λ)\n",
    "                end\n",
    "                grad_enc, grad_dec = back(1f0)\n",
    "                Flux.update!(opt_enc, enc_mdl, grad_enc) # Upd `encoder` params\n",
    "                Flux.update!(opt_dec, dec_mdl, grad_dec) # Upd `decoder` params\n",
    "                next!(progress; showvalues=[(:loss, loss)]) \n",
    "        end\n",
    "    end\n",
    "    \n",
    "    # Save the model\n",
    "    #=\n",
    "    using DrWatson: struct2dict\n",
    "    using BSON\n",
    "\n",
    "    mdl_path = joinpath(args.save_path, \"vae.bson\")\n",
    "    let args=struct2dict(args)\n",
    "    \tBSON.@save mdl_path encoder decoder args\n",
    "    \t@info \"Model saved to $(mdl_path)\"\n",
    "    end\n",
    "    =#\n",
    "    \n",
    "    enc_mdl, dec_mdl\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "94970592-419d-4779-9f21-7a7f626503f8",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[33m\u001b[1m┌ \u001b[22m\u001b[39m\u001b[33m\u001b[1mWarning: \u001b[22m\u001b[39mProgressMeter by default refresh meters with additional information in IJulia via `IJulia.clear_output`, which clears all outputs in the cell. \n",
      "\u001b[33m\u001b[1m│ \u001b[22m\u001b[39m - To prevent this behaviour, do `ProgressMeter.ijulia_behavior(:append)`. \n",
      "\u001b[33m\u001b[1m│ \u001b[22m\u001b[39m - To disable this warning message, do `ProgressMeter.ijulia_behavior(:clear)`.\n",
      "\u001b[33m\u001b[1m└ \u001b[22m\u001b[39m\u001b[90m@ ProgressMeter ~/.julia/packages/ProgressMeter/kVZZH/src/ProgressMeter.jl:594\u001b[39m\n",
      "\u001b[32mProgress:  15%|██████▎                                  |  ETA: 0:12:19\u001b[39m\n",
      "\u001b[34m  loss:  192.82417\u001b[39m"
     ]
    },
    {
     "ename": "LoadError",
     "evalue": "InterruptException:",
     "output_type": "error",
     "traceback": [
      "InterruptException:",
      "",
      "Stacktrace:",
      "  [1] _fast_broadcast!(f::ComposedFunction{typeof(identity), typeof(+)}, x::Matrix{Float32}, yz::Vector{Float32})",
      "    @ NNlib ~/.julia/packages/NNlib/mRRJu/src/utils.jl:131",
      "  [2] bias_act!",
      "    @ ~/.julia/packages/NNlib/mRRJu/src/bias_act.jl:32 [inlined]",
      "  [3] rrule",
      "    @ ~/.julia/packages/NNlib/mRRJu/src/bias_act.jl:101 [inlined]",
      "  [4] chain_rrule",
      "    @ ~/.julia/packages/Zygote/nyzjS/src/compiler/chainrules.jl:224 [inlined]",
      "  [5] macro expansion",
      "    @ ~/.julia/packages/Zygote/nyzjS/src/compiler/interface2.jl:0 [inlined]",
      "  [6] _pullback",
      "    @ ~/.julia/packages/Zygote/nyzjS/src/compiler/interface2.jl:87 [inlined]",
      "  [7] Dense",
      "    @ ~/.julia/packages/Flux/Mhg1r/src/layers/basic.jl:199 [inlined]",
      "  [8] _pullback(ctx::Zygote.Context{false}, f::Dense{typeof(identity), Matrix{Float32}, Vector{Float32}}, args::Matrix{Float32})",
      "    @ Zygote ~/.julia/packages/Zygote/nyzjS/src/compiler/interface2.jl:0",
      "  [9] _applychain",
      "    @ ~/.julia/packages/Flux/Mhg1r/src/layers/basic.jl:68 [inlined]",
      " [10] Chain",
      "    @ ~/.julia/packages/Flux/Mhg1r/src/layers/basic.jl:65 [inlined]",
      " [11] _pullback(ctx::Zygote.Context{false}, f::Chain{Tuple{Dense{typeof(tanh), Matrix{Float32}, Vector{Float32}}, Dense{typeof(identity), Matrix{Float32}, Vector{Float32}}}}, args::Matrix{Float32})",
      "    @ Zygote ~/.julia/packages/Zygote/nyzjS/src/compiler/interface2.jl:0",
      " [12] vae",
      "    @ ./In[14]:7 [inlined]",
      " [13] _pullback(::Zygote.Context{false}, ::typeof(vae), ::Matrix{Float32}, ::Encoder, ::Chain{Tuple{Dense{typeof(tanh), Matrix{Float32}, Vector{Float32}}, Dense{typeof(identity), Matrix{Float32}, Vector{Float32}}}})",
      "    @ Zygote ~/.julia/packages/Zygote/nyzjS/src/compiler/interface2.jl:0",
      " [14] l",
      "    @ ./In[15]:2 [inlined]",
      " [15] _pullback(::Zygote.Context{false}, ::typeof(l), ::Matrix{Float32}, ::Encoder, ::Chain{Tuple{Dense{typeof(tanh), Matrix{Float32}, Vector{Float32}}, Dense{typeof(identity), Matrix{Float32}, Vector{Float32}}}}, ::Float32)",
      "    @ Zygote ~/.julia/packages/Zygote/nyzjS/src/compiler/interface2.jl:0",
      " [16] #9",
      "    @ ./In[16]:17 [inlined]",
      " [17] _pullback(::Zygote.Context{false}, ::var\"#9#10\"{HyperParams, Matrix{Float32}}, ::Encoder, ::Chain{Tuple{Dense{typeof(tanh), Matrix{Float32}, Vector{Float32}}, Dense{typeof(identity), Matrix{Float32}, Vector{Float32}}}})",
      "    @ Zygote ~/.julia/packages/Zygote/nyzjS/src/compiler/interface2.jl:0",
      " [18] pullback(::Function, ::Zygote.Context{false}, ::Encoder, ::Vararg{Any})",
      "    @ Zygote ~/.julia/packages/Zygote/nyzjS/src/compiler/interface.jl:90",
      " [19] pullback",
      "    @ ~/.julia/packages/Zygote/nyzjS/src/compiler/interface.jl:88 [inlined]",
      " [20] train(; kws::@Kwargs{})",
      "    @ Main ./In[16]:16",
      " [21] train()",
      "    @ Main ./In[16]:1",
      " [22] top-level scope",
      "    @ In[17]:1"
     ]
    }
   ],
   "source": [
    "enc_model, dec_model = train()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "IJulia 1.11.2",
   "language": "julia",
   "name": "ijulia-1.11"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
